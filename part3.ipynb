{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install highway-env\n",
    "# !pip install git+https://github.com/DLR-RM/stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*env.compute_reward to get variables from other wrappers is deprecated.*\") #ignore warning\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "# Environment\n",
    "import gymnasium as gym\n",
    "from config3 import env\n",
    "\n",
    "# Agent\n",
    "from stable_baselines3 import HerReplayBuffer, SAC, PPO, A2C, DDPG, TD3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper pour aplatir les observations de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenObservation(gym.Wrapper):\n",
    "    def __init__(self, env: gym.Env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def observation(self, observation: np.ndarray) -> np.ndarray:\n",
    "        return observation.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement de modèles d'apprentissage par renforcement pour la tâche de stationnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 30_000\n",
    "train_her_sac = False\n",
    "train_sac = False\n",
    "train_ppo = False\n",
    "train_a2c = False\n",
    "train_ddpg = False\n",
    "train_td3 = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_sac:\n",
    "    env_train = FlattenObservation(deepcopy(env))\n",
    "    model = SAC('MultiInputPolicy', env_train, verbose=1,\n",
    "                tensorboard_log=\"logs\",\n",
    "                buffer_size=int(1e6),\n",
    "                learning_rate=1e-3,\n",
    "                gamma=0.95, batch_size=1024, tau=0.05,\n",
    "                learning_starts=1000,\n",
    "                device=\"cpu\",\n",
    "                policy_kwargs=dict(net_arch=[512, 512, 512]))\n",
    "    \n",
    "    model.learn(total_timesteps=int(STEPS))\n",
    "\n",
    "    model.save(\"parking_SAC/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle SAC et HER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_her_sac:\n",
    "    env_train = FlattenObservation(deepcopy(env))\n",
    "    her_kwargs = dict(n_sampled_goal=4, goal_selection_strategy='future')\n",
    "    model = SAC('MultiInputPolicy', env_train, replay_buffer_class=HerReplayBuffer,\n",
    "                replay_buffer_kwargs=her_kwargs, verbose=1,\n",
    "                tensorboard_log=\"logs\",\n",
    "                buffer_size=int(1e6),\n",
    "                learning_rate=1e-3,\n",
    "                gamma=0.95, batch_size=1024, tau=0.05,\n",
    "                learning_starts=1000,  \n",
    "                device=\"cpu\",\n",
    "                policy_kwargs=dict(net_arch=[512, 512, 512]))\n",
    "    \n",
    "    model.learn(total_timesteps=int(STEPS))\n",
    "\n",
    "    model.save(\"parking_SAC_HER/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_ppo:\n",
    "    env_train = FlattenObservation(deepcopy(env))\n",
    "    model = PPO('MultiInputPolicy', env_train, verbose=1,\n",
    "                tensorboard_log=\"logs\",\n",
    "                policy_kwargs=dict(net_arch=[512, 512, 512]),\n",
    "                learning_rate=1e-3,\n",
    "                gamma=0.95,\n",
    "                n_steps=2048,\n",
    "                ent_coef=0.0,\n",
    "                vf_coef=0.5,\n",
    "                max_grad_norm=0.5,\n",
    "                batch_size=64,\n",
    "                n_epochs=10,\n",
    "                clip_range=0.2,\n",
    "                device=\"cpu\")\n",
    "    \n",
    "    model.learn(total_timesteps=int(STEPS))\n",
    "\n",
    "    model.save(\"parking_PPO/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_a2c:\n",
    "    env_train = FlattenObservation(deepcopy(env))\n",
    "    model = A2C('MultiInputPolicy', env_train, verbose=1,\n",
    "                tensorboard_log=\"logs\",\n",
    "                policy_kwargs=dict(net_arch=[512, 512, 512]),\n",
    "                device=\"auto\",\n",
    "                n_steps=5,\n",
    "                ent_coef=0.01,\n",
    "                learning_rate=1e-3,\n",
    "                gamma=0.95,\n",
    "                vf_coef=0.5,\n",
    "                max_grad_norm=0.5)\n",
    "\n",
    "    model.learn(total_timesteps=int(STEPS))\n",
    "\n",
    "    model.save(\"parking_A2C/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_ddpg:\n",
    "    env_train = FlattenObservation(deepcopy(env))\n",
    "    model = DDPG('MultiInputPolicy', env_train, verbose=1,\n",
    "                 tensorboard_log=\"logs\",\n",
    "                 buffer_size=int(1e6),\n",
    "                 learning_rate=1e-3,\n",
    "                 gamma=0.95, batch_size=1024, tau=0.05,\n",
    "                 learning_starts=1000,\n",
    "                 device=\"cpu\",\n",
    "                 policy_kwargs=dict(net_arch=[512, 512, 512]))\n",
    "    \n",
    "    model.learn(total_timesteps=int(STEPS))\n",
    "\n",
    "    model.save(\"parking_DDPG/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_td3:\n",
    "    env_train = FlattenObservation(deepcopy(env))\n",
    "    model = TD3('MultiInputPolicy', env_train, verbose=1,\n",
    "                tensorboard_log=\"logs\",\n",
    "                buffer_size=int(1e6),\n",
    "                learning_rate=1e-3,\n",
    "                gamma=0.95, batch_size=1024, tau=0.05,\n",
    "                policy_delay=2, \n",
    "                learning_starts=1000,\n",
    "                device=\"auto\",\n",
    "                policy_kwargs=dict(net_arch=[512, 512, 512]))\n",
    "\n",
    "    model.learn(total_timesteps=int(STEPS))\n",
    "\n",
    "    model.save(\"parking_TD3/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement du modèle SAC avec HER et différentes architectures de réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_her_sac_3x512 = False\n",
    "train_her_sac_3x256 = False\n",
    "train_her_sac_3x128 = False\n",
    "train_her_sac_2x512 = True\n",
    "train_her_sac_2x256 = False\n",
    "train_her_sac_2x128 = False\n",
    "train_her_sac_4x256 = False\n",
    "train_her_sac_4x128 = False\n",
    "train_her_sac_multi = False\n",
    "train_her_sac_multi2 = False\n",
    "\n",
    "def train_her_sac_model(env, model_name, net_arch):\n",
    "    env_train = FlattenObservation(deepcopy(env))\n",
    "    her_kwargs = dict(n_sampled_goal=4, goal_selection_strategy='future')\n",
    "    model = SAC('MultiInputPolicy', env_train, replay_buffer_class=HerReplayBuffer,\n",
    "        replay_buffer_kwargs=her_kwargs, verbose=1,\n",
    "        tensorboard_log=\"logs\",\n",
    "        buffer_size=int(1e6),\n",
    "        learning_rate=1e-3,\n",
    "        gamma=0.95, batch_size=1024, tau=0.05,\n",
    "        learning_starts=1000,\n",
    "        device=\"cpu\",\n",
    "        policy_kwargs=dict(net_arch=net_arch))\n",
    "    model.learn(total_timesteps=int(STEPS))\n",
    "    model.save(f\"parking_SAC_HER_{model_name}/model\")\n",
    "\n",
    "if train_her_sac_3x512:\n",
    "    train_her_sac_model(env, \"train_her_sac_3x512\", [512, 512, 512])\n",
    "\n",
    "if train_her_sac_3x256:\n",
    "    train_her_sac_model(env, \"train_her_sac_3x256\", [256, 256, 256])\n",
    "\n",
    "if train_her_sac_3x128:\n",
    "    train_her_sac_model(env, \"train_her_sac_3x128\", [128, 128, 128])\n",
    "\n",
    "if train_her_sac_2x512:\n",
    "    train_her_sac_model(env, \"train_her_sac_2x512\", [512, 512])\n",
    "\n",
    "if train_her_sac_2x256:\n",
    "    train_her_sac_model(env, \"train_her_sac_2x256\", [256, 256])\n",
    "\n",
    "if train_her_sac_2x128:\n",
    "    train_her_sac_model(env, \"train_her_sac_2x128\", [128, 128])\n",
    "\n",
    "if train_her_sac_4x256:\n",
    "    train_her_sac_model(env, \"train_her_sac_4x256\", [256, 256, 256, 256])\n",
    "\n",
    "if train_her_sac_4x128:\n",
    "    train_her_sac_model(env, \"train_her_sac_4x128\", [128, 128, 128, 128])\n",
    "\n",
    "if train_her_sac_multi:\n",
    "    train_her_sac_model(env, \"train_her_sac_multi\", [128, 256, 128])\n",
    "\n",
    "if train_her_sac_multi2:\n",
    "    train_her_sac_model(env, \"train_her_sac_multi2\", [256, 512, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage et enregistrement de la voiture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage de la voiture se garant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_her_sac = False\n",
    "\n",
    "if display_her_sac:\n",
    "    env_display = FlattenObservation(deepcopy(env))\n",
    "    model = SAC.load(\"parking_SAC_HER_train_her_sac_3x256/model\", env=env_display)\n",
    "    for i in range(10):\n",
    "        obs, info = env_display.reset()\n",
    "        done = truncated = False\n",
    "        while not (done or truncated):\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, truncated, info = env_display.step(action)\n",
    "            env_display.render()\n",
    "\n",
    "        print(i, info['is_success'])\n",
    "    env_display.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enregistrement des images de fails, pour connaître leurs causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fails = False\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Créer un dossier pour stocker les images\n",
    "if not os.path.exists('failed_images'):\n",
    "    os.makedirs('failed_images')\n",
    "\n",
    "if save_fails:\n",
    "    env_display = FlattenObservation(deepcopy(env))\n",
    "    model = SAC.load(\"parking_SAC_HER_train_her_sac_3x256/model\", env=env_display)\n",
    "    for i in range(2000):\n",
    "        obs, info = env_display.reset()\n",
    "        done = truncated = False\n",
    "        j=0\n",
    "        while not (done or truncated):\n",
    "            j+=1\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, truncated, info = env_display.step(action)\n",
    "        \n",
    "\n",
    "        # Enregistrer la dernière image si is_success est False\n",
    "        if not info['is_success']:\n",
    "            print(i, j, info['is_success'])\n",
    "            last_image = env_display.render()\n",
    "            if last_image is not None:\n",
    "                cv2.imwrite(os.path.join('failed_images', f'image_{i}.png'), last_image)\n",
    "\n",
    "\n",
    "    env_display.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage des statistiques d'entrainement avec TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14490), started 21:38:02 ago. (Use '!kill 14490' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2d8e286f782538bf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2d8e286f782538bf\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n",
    "\n",
    "\n",
    "\n",
    "# http://localhost:6006\n",
    "\n",
    "# Ctrl/Cmd + Shift + P\n",
    "# Python: Launch TensorBoard\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
